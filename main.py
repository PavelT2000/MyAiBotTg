import os
import logging
import asyncio
from io import BytesIO
from typing import Optional

from aiogram import Bot, Dispatcher, types, F
from aiogram.filters import Command
from aiogram.types import Message
from aiogram.utils.keyboard import ReplyKeyboardBuilder
import openai

from config import config  # –ò–º–ø–æ—Ä—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –∏–∑ config.py

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–∞ OpenAI
client = openai.AsyncOpenAI(api_key=config.OPENAI_API_KEY)

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–æ—Ç–∞
bot = Bot(token=config.TELEGRAM_BOT_TOKEN)
dp = Dispatcher()

# –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞
async def create_assistant():
    try:
        assistant = await client.beta.assistants.create(
            name="Voice Assistant",
            instructions="–í—ã –ø–æ–ª–µ–∑–Ω—ã–π –≥–æ–ª–æ—Å–æ–≤–æ–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç, –æ—Ç–≤–µ—á–∞—é—â–∏–π –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –∫—Ä–∞—Ç–∫–æ –∏ –ø–æ –¥–µ–ª—É.",
            model="gpt-4o",
            tools=[{"type": "code_interpreter"}]  # –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ
        )
        logger.info(f"–°–æ–∑–¥–∞–Ω –Ω–æ–≤—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç —Å ID: {assistant.id}")
        print(f"!!! –í–ê–ñ–ù–û: –î–æ–±–∞–≤—å—Ç–µ –≤ .env —Å–ª–µ–¥—É—é—â–∏–π ASSISTANT_ID: {assistant.id}")
        return assistant.id
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞: {e}")
        raise

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏ —Å–æ–∑–¥–∞–Ω–∏–µ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞, –µ—Å–ª–∏ ID –Ω–µ–¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª–µ–Ω
async def verify_or_create_assistant():
    try:
        assistant = await client.beta.assistants.retrieve(config.ASSISTANT_ID)
        logger.info(f"–ê—Å—Å–∏—Å—Ç–µ–Ω—Ç –Ω–∞–π–¥–µ–Ω: {assistant.name}")
        return config.ASSISTANT_ID
    except openai.NotFoundError:
        logger.warning(f"–ê—Å—Å–∏—Å—Ç–µ–Ω—Ç —Å ID {config.ASSISTANT_ID} –Ω–µ –Ω–∞–π–¥–µ–Ω. –°–æ–∑–¥–∞—ë–º –Ω–æ–≤—ã–π...")
        new_assistant_id = await create_assistant()
        # –û–±–Ω–æ–≤–ª—è–µ–º config.ASSISTANT_ID (–Ω–æ .env –Ω—É–∂–Ω–æ –æ–±–Ω–æ–≤–∏—Ç—å –≤—Ä—É—á–Ω—É—é)
        config.ASSISTANT_ID = new_assistant_id
        logger.info(f"–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –Ω–æ–≤—ã–π ASSISTANT_ID: {new_assistant_id}")
        return new_assistant_id
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞: {e}")
        raise

# –ö–ª–∞–≤–∏–∞—Ç—É—Ä–∞
def get_main_keyboard():
    builder = ReplyKeyboardBuilder()
    builder.button(text="–ü–æ–º–æ—â—å")
    builder.button(text="–û –±–æ—Ç–µ")
    return builder.as_markup(resize_keyboard=True)

# –û–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏–π
@dp.message(Command("start"))
async def start_handler(message: Message):
    await message.answer(
        "–ü—Ä–∏–≤–µ—Ç! –û—Ç–ø—Ä–∞–≤—å –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ, –∏ —è –æ—Ç–≤–µ—á—É –≥–æ–ª–æ—Å–æ–º!",
        reply_markup=get_main_keyboard()
    )

@dp.message(F.text)
async def text_handler(message: Message):
    if message.text.lower() == "–ø–æ–º–æ—â—å":
        await message.answer("–ü—Ä–æ—Å—Ç–æ –æ—Ç–ø—Ä–∞–≤—å –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ —Å –≤–æ–ø—Ä–æ—Å–æ–º")
    elif message.text.lower() == "–æ –±–æ—Ç–µ":
        await message.answer("–Ø –≥–æ–ª–æ—Å–æ–≤–æ–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –Ω–∞ OpenAI API")
    else:
        await message.answer("–ò—Å–ø–æ–ª—å–∑—É–π –≥–æ–ª–æ—Å–æ–≤—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è")

@dp.message(F.voice)
async def voice_handler(message: Message):
    try:
        # 1. –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≥–æ–ª–æ—Å–∞ –≤ —Ç–µ–∫—Å—Ç (Whisper API)
        voice_file = await bot.get_file(message.voice.file_id)
        voice_data = await bot.download_file(voice_file.file_path)
        
        transcript = await client.audio.transcriptions.create(
            file=("voice.ogg", BytesIO(voice_data.read()), "audio/ogg"),
            model="whisper-1"
        )
        user_question = transcript.text
        await message.answer(f"üé§ –í–∞—à –≤–æ–ø—Ä–æ—Å: {user_question}")

        # 2. –ü–æ–ª—É—á–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ —á–µ—Ä–µ–∑ Assistant API
        thread = await client.beta.threads.create()
        await client.beta.threads.messages.create(
            thread_id=thread.id,
            role="user",
            content=user_question
        )
        
        run = await client.beta.threads.runs.create(
            thread_id=thread.id,
            assistant_id=config.ASSISTANT_ID
        )
        
        while True:
            run_status = await client.beta.threads.runs.retrieve(
                thread_id=thread.id,
                run_id=run.id
            )
            if run_status.status == "completed":
                break
            await asyncio.sleep(1)
        
        messages = await client.beta.threads.messages.list(thread_id=thread.id)
        assistant_response = next(
            m.content[0].text.value 
            for m in messages.data 
            if m.role == "assistant"
        )

        # 3. –û–∑–≤—É—á–∫–∞ –æ—Ç–≤–µ—Ç–∞ (TTS API)
        speech = await client.audio.speech.create(
            model="tts-1",
            voice="alloy",
            input=assistant_response
        )
        
        await message.answer_voice(
            types.BufferedInputFile(
                (await speech.aread()),
                filename="response.mp3"
            )
        )
        await message.answer(f"ü§ñ –û—Ç–≤–µ—Ç: {assistant_response}")

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞: {e}", exc_info=True)
        await message.answer("–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø—Ä–æ—Å–∞")

async def main():
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏–ª–∏ —Å–æ–∑–¥–∞—ë–º –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ –ø–µ—Ä–µ–¥ –∑–∞–ø—É—Å–∫–æ–º –±–æ—Ç–∞
    await verify_or_create_assistant()
    await dp.start_polling(bot)

if __name__ == "__main__":
    asyncio.run(main())